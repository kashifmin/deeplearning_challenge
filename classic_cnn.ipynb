{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL.Image as img\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "INPUT_RES = 32\n",
    "learning_rate = 0.001\n",
    "names = ['rice', 'candy', 'jam', 'coffee', 'vinegar', 'chocolate', 'sugar', 'water', 'juice', 'milk', 'soda', 'nuts', 'chips', 'spices', 'cereal', 'beans', 'cake', 'honey', 'flour', 'pasta', 'tomatosauce', 'tea', 'corn', 'oil', 'fish']\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTrainData():\n",
    "    size = INPUT_RES, INPUT_RES\n",
    "    dataFiles = csv.reader(open('./data/train.csv'), delimiter=',')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for imName, label in dataFiles:\n",
    "        if imName == 'image_id':\n",
    "            continue\n",
    "        im = img.open('./data/train_img/' + imName + '.png').convert('L').resize(size, img.ANTIALIAS)\n",
    "        data.append(np.asarray(im).reshape(32*32))\n",
    "        labels.append(names.index(label)+1)\n",
    "        \n",
    "    return np.asarray(data), labels\n",
    "    \n",
    "    \n",
    "    \n",
    "#     image = img.open('data/train_img/train_2a.png')\n",
    "#     size = INPUT_RES, INPUT_RES\n",
    "#     image = image.convert('L').resize(size, img.ANTIALIAS)\n",
    "#     #print(image.split()[0])\n",
    "#     print(image)\n",
    "#     #image.show()\n",
    "#     print(np.asarray(image).shape)\n",
    "    \n",
    "data, labels = readTrainData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.shape)\n",
    "# print(len(labels))\\\n",
    "# 26 classes\n",
    "NCLASSES = 25\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 32 * 32])\n",
    "y = tf.placeholder(tf.float32, [None, NCLASSES])\n",
    "W1 = tf.Variable(tf.random_normal([5, 5, 1, 64]))\n",
    "b1 = tf.Variable(tf.random_normal([64]))\n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 64, 64]))\n",
    "b2 = tf.Variable(tf.random_normal([64]))\n",
    "W3 = tf.Variable(tf.random_normal([8*8*64, 1024]))\n",
    "b3 = tf.Variable(tf.random_normal([1024]))\n",
    "W_out = tf.Variable(tf.random_normal([1024, NCLASSES]))\n",
    "b_out = tf.Variable(tf.random_normal([NCLASSES]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(x, W, b):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv_with_b = tf.nn.bias_add(conv, b)\n",
    "    conv_out = tf.nn.relu(conv_with_b)\n",
    "    return conv_out\n",
    "\n",
    "\n",
    "def maxpool_layer(conv, k=2):\n",
    "    return tf.nn.max_pool(conv, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    #x_reshaped = tf.reshape(x, shape=[-1, 32, 32, 1])\n",
    "    x_reshaped = tf.reshape(x, shape=[-1, 32, 32, 1])\n",
    "    conv_out1 = conv_layer(x_reshaped, W1, b1)\n",
    "    maxpool_out1 = maxpool_layer(conv_out1)\n",
    "    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    conv_out2 = conv_layer(norm1, W2, b2)\n",
    "    norm2 = tf.nn.lrn(conv_out2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    maxpool_out2 = maxpool_layer(norm2)\n",
    "\n",
    "    maxpool_reshaped = tf.reshape(maxpool_out2, [-1, W3.get_shape().as_list()[0]])\n",
    "    local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)\n",
    "    local_out = tf.nn.relu(local)\n",
    "\n",
    "    out = tf.add(tf.matmul(local_out, W_out), b_out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_op = model()\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=model_op, labels=y)\n",
    ")\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(model_op, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 16\n",
      "Epoch 0. Avg accuracy 0.05881011612083188\n",
      "Epoch 1. Avg accuracy 0.07837893865743087\n",
      "Epoch 2. Avg accuracy 0.09425787731486174\n",
      "Epoch 3. Avg accuracy 0.10638474298650352\n",
      "Epoch 4. Avg accuracy 0.1343490879111622\n",
      "Epoch 5. Avg accuracy 0.14210199004975124\n",
      "Epoch 6. Avg accuracy 0.15366915431781789\n",
      "Epoch 7. Avg accuracy 0.14769900497512436\n",
      "Epoch 8. Avg accuracy 0.16050995033771837\n",
      "Epoch 9. Avg accuracy 0.19036069660637508\n",
      "Epoch 10. Avg accuracy 0.18194444447904085\n",
      "Epoch 11. Avg accuracy 0.19716003318479405\n",
      "Epoch 12. Avg accuracy 0.20400082920469456\n",
      "Epoch 13. Avg accuracy 0.2161898839829573\n",
      "Epoch 14. Avg accuracy 0.22796434497655327\n",
      "Epoch 15. Avg accuracy 0.23667081263824483\n",
      "Epoch 16. Avg accuracy 0.2541252073660419\n",
      "Epoch 17. Avg accuracy 0.272802653597362\n",
      "Epoch 18. Avg accuracy 0.2730928690575842\n",
      "Epoch 19. Avg accuracy 0.2712064677506537\n",
      "Epoch 20. Avg accuracy 0.2908167496545991\n",
      "Epoch 21. Avg accuracy 0.2826907131357573\n",
      "Epoch 22. Avg accuracy 0.3056799336823065\n",
      "Epoch 23. Avg accuracy 0.3135157546297235\n",
      "Epoch 24. Avg accuracy 0.32568407977991437\n",
      "Epoch 25. Avg accuracy 0.3390339968809441\n",
      "Epoch 26. Avg accuracy 0.3337271974157931\n",
      "Epoch 27. Avg accuracy 0.3520522388949323\n",
      "Epoch 28. Avg accuracy 0.3458747927525743\n",
      "Epoch 29. Avg accuracy 0.3860281925296309\n",
      "Epoch 30. Avg accuracy 0.36884328367105174\n",
      "Epoch 31. Avg accuracy 0.37819237154514634\n",
      "Epoch 32. Avg accuracy 0.415899668463427\n",
      "Epoch 33. Avg accuracy 0.41861525711728564\n",
      "Epoch 34. Avg accuracy 0.42238805987941686\n",
      "Epoch 35. Avg accuracy 0.43389303500379495\n",
      "Epoch 36. Avg accuracy 0.4547263683371283\n",
      "Epoch 37. Avg accuracy 0.4547470980022677\n",
      "Epoch 38. Avg accuracy 0.49365671653652665\n",
      "Epoch 39. Avg accuracy 0.514759535813213\n",
      "Epoch 40. Avg accuracy 0.5240878940221683\n",
      "Epoch 41. Avg accuracy 0.5551202322416637\n",
      "Epoch 42. Avg accuracy 0.5617744614235798\n",
      "Epoch 43. Avg accuracy 0.5916044777305565\n",
      "Epoch 44. Avg accuracy 0.6115257052046743\n",
      "Epoch 45. Avg accuracy 0.6423092872942265\n",
      "Epoch 46. Avg accuracy 0.6519900501070924\n",
      "Epoch 47. Avg accuracy 0.6563640136030776\n",
      "Epoch 48. Avg accuracy 0.6837271976826796\n",
      "Epoch 49. Avg accuracy 0.7058250417756797\n",
      "Epoch 50. Avg accuracy 0.7008499173975703\n",
      "Epoch 51. Avg accuracy 0.7001658375583478\n",
      "Epoch 52. Avg accuracy 0.7032131015957884\n",
      "Epoch 53. Avg accuracy 0.7434079605548536\n",
      "Epoch 54. Avg accuracy 0.7337686570722666\n",
      "Epoch 55. Avg accuracy 0.7458955227439084\n",
      "Epoch 56. Avg accuracy 0.7558250418349878\n",
      "Epoch 57. Avg accuracy 0.768262852483721\n",
      "Epoch 58. Avg accuracy 0.7477819240508388\n",
      "Epoch 59. Avg accuracy 0.7762645109375911\n",
      "Epoch 60. Avg accuracy 0.7667703154075205\n",
      "Epoch 61. Avg accuracy 0.7465588726214508\n",
      "Epoch 62. Avg accuracy 0.7561152574434802\n",
      "Epoch 63. Avg accuracy 0.7707504146727756\n",
      "Epoch 64. Avg accuracy 0.7639510782796946\n",
      "Epoch 65. Avg accuracy 0.7400290218751822\n",
      "Epoch 66. Avg accuracy 0.772014925728983\n",
      "Epoch 67. Avg accuracy 0.7632669987370125\n",
      "Epoch 68. Avg accuracy 0.774834162856809\n",
      "Epoch 69. Avg accuracy 0.7484245442632419\n",
      "Epoch 70. Avg accuracy 0.7635986736757838\n",
      "Epoch 71. Avg accuracy 0.7701492540871919\n",
      "Epoch 72. Avg accuracy 0.7732794364886497\n",
      "Epoch 73. Avg accuracy 0.756426202717112\n",
      "Epoch 74. Avg accuracy 0.7533374793493925\n",
      "Epoch 75. Avg accuracy 0.7558457715001272\n",
      "Epoch 76. Avg accuracy 0.7618159203980099\n",
      "Epoch 77. Avg accuracy 0.7145107797722319\n",
      "Epoch 78. Avg accuracy 0.7561152574434802\n",
      "Epoch 79. Avg accuracy 0.7453358208955224\n",
      "Epoch 80. Avg accuracy 0.7595978444488487\n",
      "Epoch 81. Avg accuracy 0.7753938644086543\n",
      "Epoch 82. Avg accuracy 0.7262852408399629\n",
      "Epoch 83. Avg accuracy 0.72104063022196\n",
      "Epoch 84. Avg accuracy 0.7487147598717343\n",
      "Epoch 85. Avg accuracy 0.7495439470703922\n",
      "Epoch 86. Avg accuracy 0.7169568826310078\n",
      "Epoch 87. Avg accuracy 0.7505597018483859\n",
      "Epoch 88. Avg accuracy 0.7421641794603262\n",
      "Epoch 89. Avg accuracy 0.7431592039800995\n",
      "Epoch 90. Avg accuracy 0.7393449423325003\n",
      "Epoch 91. Avg accuracy 0.7284825874205253\n",
      "Epoch 92. Avg accuracy 0.7290837483026495\n",
      "Epoch 93. Avg accuracy 0.7126658377955802\n",
      "Epoch 94. Avg accuracy 0.7446102823191021\n",
      "Epoch 95. Avg accuracy 0.7047885573325465\n",
      "Epoch 96. Avg accuracy 0.7216625210657641\n",
      "Epoch 97. Avg accuracy 0.725062189410575\n",
      "Epoch 98. Avg accuracy 0.7169568826310078\n",
      "Epoch 99. Avg accuracy 0.7026326703788036\n",
      "Epoch 100. Avg accuracy 0.7084991709509892\n",
      "Epoch 101. Avg accuracy 0.7253524047225269\n",
      "Epoch 102. Avg accuracy 0.7359867333179683\n",
      "Epoch 103. Avg accuracy 0.7191334992498901\n",
      "Epoch 104. Avg accuracy 0.7247719738020826\n",
      "Epoch 105. Avg accuracy 0.7241500832548189\n",
      "Epoch 106. Avg accuracy 0.707379768143839\n",
      "Epoch 107. Avg accuracy 0.7010572140489645\n",
      "Epoch 108. Avg accuracy 0.7055348258706468\n",
      "Epoch 109. Avg accuracy 0.7014510782796946\n",
      "Epoch 110. Avg accuracy 0.7306177450056693\n",
      "Epoch 111. Avg accuracy 0.7172885575697789\n",
      "Epoch 112. Avg accuracy 0.7004975127936596\n",
      "Epoch 113. Avg accuracy 0.6774875625449034\n",
      "Epoch 114. Avg accuracy 0.7029021560256161\n",
      "Epoch 115. Avg accuracy 0.7107794364886497\n",
      "Epoch 116. Avg accuracy 0.6970563851185699\n",
      "Epoch 117. Avg accuracy 0.6958126040240425\n",
      "Epoch 118. Avg accuracy 0.6920605310753211\n",
      "Epoch 119. Avg accuracy 0.7091832507902117\n",
      "Epoch 120. Avg accuracy 0.6883291877917389\n",
      "Epoch 121. Avg accuracy 0.7247305141752632\n",
      "Epoch 122. Avg accuracy 0.7163971810791623\n",
      "Epoch 123. Avg accuracy 0.6999170815766748\n",
      "Epoch 124. Avg accuracy 0.713246269012565\n",
      "Epoch 125. Avg accuracy 0.7001865675200277\n",
      "Epoch 126. Avg accuracy 0.6725331678319333\n",
      "Epoch 127. Avg accuracy 0.6696932007424274\n",
      "Epoch 128. Avg accuracy 0.6939883917125304\n",
      "Epoch 129. Avg accuracy 0.6936774461423579\n",
      "Epoch 130. Avg accuracy 0.7210613601836399\n",
      "Epoch 131. Avg accuracy 0.7135779439513363\n",
      "Epoch 132. Avg accuracy 0.7023424547703112\n",
      "Epoch 133. Avg accuracy 0.739966832879764\n",
      "Epoch 134. Avg accuracy 0.7023217251051718\n",
      "Epoch 135. Avg accuracy 0.6827321728663658\n",
      "Epoch 136. Avg accuracy 0.68026534004591\n",
      "Epoch 137. Avg accuracy 0.7175787731782713\n",
      "Epoch 138. Avg accuracy 0.7110696520971421\n",
      "Epoch 139. Avg accuracy 0.6836650086872613\n",
      "Epoch 140. Avg accuracy 0.7191956885418489\n",
      "Epoch 141. Avg accuracy 0.7232172474339233\n",
      "Epoch 142. Avg accuracy 0.710157545941386\n",
      "Epoch 143. Avg accuracy 0.6995439473076246\n",
      "Epoch 144. Avg accuracy 0.695812603727502\n",
      "Epoch 145. Avg accuracy 0.7079394693991438\n",
      "Epoch 146. Avg accuracy 0.693698176104038\n",
      "Epoch 147. Avg accuracy 0.6957918743589031\n",
      "Epoch 148. Avg accuracy 0.6949004978682864\n",
      "Epoch 149. Avg accuracy 0.6691334994871225\n",
      "Epoch 150. Avg accuracy 0.6921019904055998\n",
      "Epoch 151. Avg accuracy 0.7226160865517991\n",
      "Epoch 152. Avg accuracy 0.6892205639858151\n",
      "Epoch 153. Avg accuracy 0.6969941958266112\n",
      "Epoch 154. Avg accuracy 0.6939883917125304\n",
      "Epoch 155. Avg accuracy 0.7036069655299779\n",
      "Epoch 156. Avg accuracy 0.6933665011652667\n",
      "Epoch 157. Avg accuracy 0.6830638475085965\n",
      "Epoch 158. Avg accuracy 0.7163142624186046\n",
      "Epoch 159. Avg accuracy 0.6843283585648039\n",
      "Epoch 160. Avg accuracy 0.696475953901585\n",
      "Epoch 161. Avg accuracy 0.7107587068235103\n",
      "Epoch 162. Avg accuracy 0.6786898843091519\n",
      "Epoch 163. Avg accuracy 0.6945688229295152\n",
      "Epoch 164. Avg accuracy 0.6827736321966447\n",
      "Epoch 165. Avg accuracy 0.7110281927668634\n",
      "Epoch 166. Avg accuracy 0.6905265343723013\n",
      "Epoch 167. Avg accuracy 0.7091625211250723\n",
      "Epoch 168. Avg accuracy 0.6886815923956496\n",
      "Epoch 169. Avg accuracy 0.6915008295234756\n",
      "Epoch 170. Avg accuracy 0.6921019904055998\n",
      "Epoch 171. Avg accuracy 0.6905887233677195\n",
      "Epoch 172. Avg accuracy 0.6906094527363185\n",
      "Epoch 173. Avg accuracy 0.6944859039724169\n",
      "Epoch 174. Avg accuracy 0.6918532338308457\n",
      "Epoch 175. Avg accuracy 0.6967661695100775\n",
      "Epoch 176. Avg accuracy 0.7048922059547842\n",
      "Epoch 177. Avg accuracy 0.6998963519115353\n",
      "Epoch 178. Avg accuracy 0.6896351578816846\n",
      "Epoch 179. Avg accuracy 0.7044983420205947\n",
      "Epoch 180. Avg accuracy 0.6908167499807937\n",
      "Epoch 181. Avg accuracy 0.7008084580672914\n",
      "Epoch 182. Avg accuracy 0.6855306803290524\n",
      "Epoch 183. Avg accuracy 0.691148424919565\n",
      "Epoch 184. Avg accuracy 0.689904643528497\n",
      "Epoch 185. Avg accuracy 0.6799958543990975\n",
      "Epoch 186. Avg accuracy 0.7151119406543561\n",
      "Epoch 187. Avg accuracy 0.720750414910008\n",
      "Epoch 188. Avg accuracy 0.6796434497951869\n",
      "Epoch 189. Avg accuracy 0.6591210617354853\n",
      "Epoch 190. Avg accuracy 0.6848880598201087\n",
      "Epoch 191. Avg accuracy 0.651015754955918\n",
      "Epoch 192. Avg accuracy 0.6731135987523776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193. Avg accuracy 0.6569029851932431\n",
      "Epoch 194. Avg accuracy 0.6771351579409927\n",
      "Epoch 195. Avg accuracy 0.6930140962648155\n",
      "Epoch 196. Avg accuracy 0.6771766172712715\n",
      "Epoch 197. Avg accuracy 0.6955431180806896\n",
      "Epoch 198. Avg accuracy 0.7039593701338887\n",
      "Epoch 199. Avg accuracy 0.702529021756566\n",
      "Epoch 200. Avg accuracy 0.6703150915862316\n",
      "Epoch 201. Avg accuracy 0.6911898842498437\n",
      "Epoch 202. Avg accuracy 0.7129353237389332\n",
      "Epoch 203. Avg accuracy 0.6935530681515214\n",
      "Epoch 204. Avg accuracy 0.7160240468101122\n",
      "Epoch 205. Avg accuracy 0.6799543947722781\n",
      "Epoch 206. Avg accuracy 0.6674958544584056\n",
      "Epoch 207. Avg accuracy 0.7070273635399282\n",
      "Epoch 208. Avg accuracy 0.7188018246076593\n",
      "Epoch 209. Avg accuracy 0.6861525708763161\n",
      "Epoch 210. Avg accuracy 0.6992537316991322\n",
      "Epoch 211. Avg accuracy 0.652922885927988\n",
      "Epoch 212. Avg accuracy 0.6908582093110726\n",
      "Epoch 213. Avg accuracy 0.6790422889130625\n",
      "Epoch 214. Avg accuracy 0.6991915424071734\n",
      "Epoch 215. Avg accuracy 0.7281716421468934\n",
      "Epoch 216. Avg accuracy 0.7076285244220525\n",
      "Epoch 217. Avg accuracy 0.6992537316991322\n",
      "Epoch 218. Avg accuracy 0.6560323386643063\n",
      "Epoch 219. Avg accuracy 0.7216625210657641\n",
      "Epoch 220. Avg accuracy 0.6905472640374407\n",
      "Epoch 221. Avg accuracy 0.7009950250535462\n",
      "Epoch 222. Avg accuracy 0.6958747930194608\n",
      "Epoch 223. Avg accuracy 0.6691334994871225\n",
      "Epoch 224. Avg accuracy 0.688308457830059\n",
      "Epoch 225. Avg accuracy 0.7126036485036215\n",
      "Epoch 226. Avg accuracy 0.7150497513623973\n",
      "Epoch 227. Avg accuracy 0.722242952282749\n",
      "Epoch 228. Avg accuracy 0.7172470982395002\n",
      "Epoch 229. Avg accuracy 0.7224295191207335\n",
      "Epoch 230. Avg accuracy 0.6799543947722781\n",
      "Epoch 231. Avg accuracy 0.7060737980538933\n",
      "Epoch 232. Avg accuracy 0.6864842455185468\n",
      "Epoch 233. Avg accuracy 0.6867951907921787\n",
      "Epoch 234. Avg accuracy 0.6920812607404605\n",
      "Epoch 235. Avg accuracy 0.7218698180136989\n",
      "Epoch 236. Avg accuracy 0.667247098180192\n",
      "Epoch 237. Avg accuracy 0.7567786073210228\n",
      "Epoch 238. Avg accuracy 0.6721393036012032\n",
      "Epoch 239. Avg accuracy 0.6921434497358787\n",
      "Epoch 240. Avg accuracy 0.6918532338308457\n",
      "Epoch 241. Avg accuracy 0.7160240468101122\n",
      "Epoch 242. Avg accuracy 0.6982379769211384\n",
      "Epoch 243. Avg accuracy 0.6942578776558833\n",
      "Epoch 244. Avg accuracy 0.7060737980538933\n",
      "Epoch 245. Avg accuracy 0.7017205642230475\n",
      "Epoch 246. Avg accuracy 0.6957504150286242\n",
      "Epoch 247. Avg accuracy 0.6724709788365151\n",
      "Epoch 248. Avg accuracy 0.7082711446344556\n",
      "Epoch 249. Avg accuracy 0.6827114429046859\n",
      "Epoch 250. Avg accuracy 0.6745854064599791\n",
      "Epoch 251. Avg accuracy 0.7162313434615064\n",
      "Epoch 252. Avg accuracy 0.6808457712628948\n",
      "Epoch 253. Avg accuracy 0.6808872308897141\n",
      "Epoch 254. Avg accuracy 0.698237977217679\n",
      "Epoch 255. Avg accuracy 0.7029436156524355\n",
      "Epoch 256. Avg accuracy 0.6696724713738285\n",
      "Epoch 257. Avg accuracy 0.6966832505529793\n",
      "Epoch 258. Avg accuracy 0.6774461032146245\n",
      "Epoch 259. Avg accuracy 0.6734452739876894\n",
      "Epoch 260. Avg accuracy 0.6991708130385745\n",
      "Epoch 261. Avg accuracy 0.6901119404764318\n",
      "Epoch 262. Avg accuracy 0.6923507463872729\n",
      "Epoch 263. Avg accuracy 0.6967247101797986\n",
      "Epoch 264. Avg accuracy 0.7140961861729029\n",
      "Epoch 265. Avg accuracy 0.6777777778568552\n",
      "Epoch 266. Avg accuracy 0.6917703154668287\n",
      "Epoch 267. Avg accuracy 0.6861940302065949\n",
      "Epoch 268. Avg accuracy 0.6786691543474719\n",
      "Epoch 269. Avg accuracy 0.6873756220091635\n",
      "Epoch 270. Avg accuracy 0.6799336654036793\n",
      "Epoch 271. Avg accuracy 0.6811774464982066\n",
      "Epoch 272. Avg accuracy 0.727197346995719\n",
      "Epoch 273. Avg accuracy 0.7076285241255119\n",
      "Epoch 274. Avg accuracy 0.6901741294718501\n",
      "Epoch 275. Avg accuracy 0.7129145940737938\n",
      "Epoch 276. Avg accuracy 0.6967868988786764\n",
      "Epoch 277. Avg accuracy 0.6721393036012032\n",
      "Epoch 278. Avg accuracy 0.6644278610523661\n",
      "Epoch 279. Avg accuracy 0.711650083314127\n",
      "Epoch 280. Avg accuracy 0.6790008295827837\n",
      "Epoch 281. Avg accuracy 0.6737976785916001\n",
      "Epoch 282. Avg accuracy 0.6960613603022561\n",
      "Epoch 283. Avg accuracy 0.6814676618101585\n",
      "Epoch 284. Avg accuracy 0.6925995026654865\n",
      "Epoch 285. Avg accuracy 0.6887023220607891\n",
      "Epoch 286. Avg accuracy 0.7019485905395811\n",
      "Epoch 287. Avg accuracy 0.7179726368159204\n",
      "Epoch 288. Avg accuracy 0.6811774464982066\n",
      "Epoch 289. Avg accuracy 0.7088515758514404\n",
      "Epoch 290. Avg accuracy 0.6871268660274904\n",
      "Epoch 291. Avg accuracy 0.6756011612379729\n",
      "Epoch 292. Avg accuracy 0.6690920401568436\n",
      "Epoch 293. Avg accuracy 0.7060323384270739\n",
      "Epoch 294. Avg accuracy 0.6762230517852366\n",
      "Epoch 295. Avg accuracy 0.666873963911142\n",
      "Epoch 296. Avg accuracy 0.702653400043943\n",
      "Epoch 297. Avg accuracy 0.6759328361767442\n",
      "Epoch 298. Avg accuracy 0.6799336654036793\n",
      "Epoch 299. Avg accuracy 0.6775082922100428\n",
      "Epoch 300. Avg accuracy 0.688308457830059\n",
      "Epoch 301. Avg accuracy 0.6802653403424505\n",
      "Epoch 302. Avg accuracy 0.6790215592479232\n",
      "Epoch 303. Avg accuracy 0.7008084580672914\n",
      "Epoch 304. Avg accuracy 0.7212686568350342\n",
      "Epoch 305. Avg accuracy 0.7080016586911025\n",
      "Epoch 306. Avg accuracy 0.697947761312646\n",
      "Epoch 307. Avg accuracy 0.6718283583275715\n",
      "Epoch 308. Avg accuracy 0.6728648427707046\n",
      "Epoch 309. Avg accuracy 0.6746683251205369\n",
      "Epoch 310. Avg accuracy 0.7023631844354506\n",
      "Epoch 311. Avg accuracy 0.693926202717112\n",
      "Epoch 312. Avg accuracy 0.6374170815766748\n",
      "Epoch 313. Avg accuracy 0.6736733006007636\n",
      "Epoch 314. Avg accuracy 0.6966832508495198\n",
      "Epoch 315. Avg accuracy 0.6768242126673608\n",
      "Epoch 316. Avg accuracy 0.6734038146574106\n",
      "Epoch 317. Avg accuracy 0.6506633503520074\n",
      "Epoch 318. Avg accuracy 0.6977197349961124\n",
      "Epoch 319. Avg accuracy 0.6826907132395464\n",
      "Epoch 320. Avg accuracy 0.6603855724951521\n",
      "Epoch 321. Avg accuracy 0.6989220564638204\n",
      "Epoch 322. Avg accuracy 0.6429311778414902\n",
      "Epoch 323. Avg accuracy 0.7195273631840796\n",
      "Epoch 324. Avg accuracy 0.6743781098085849\n",
      "Epoch 325. Avg accuracy 0.7424543950688186\n",
      "Epoch 326. Avg accuracy 0.6970563851185699\n",
      "Epoch 327. Avg accuracy 0.6544983419612865\n",
      "Epoch 328. Avg accuracy 0.670335821251371\n",
      "Epoch 329. Avg accuracy 0.662562189410575\n",
      "Epoch 330. Avg accuracy 0.6964552242364457\n",
      "Epoch 331. Avg accuracy 0.7098258710026148\n",
      "Epoch 332. Avg accuracy 0.705203151228416\n",
      "Epoch 333. Avg accuracy 0.6952114431419183\n",
      "Epoch 334. Avg accuracy 0.6663349920244359\n",
      "Epoch 335. Avg accuracy 0.6948383085763277\n",
      "Epoch 336. Avg accuracy 0.6600124379295614\n",
      "Epoch 337. Avg accuracy 0.684017413291172\n",
      "Epoch 338. Avg accuracy 0.661339137981187\n",
      "Epoch 339. Avg accuracy 0.6849295194469281\n",
      "Epoch 340. Avg accuracy 0.6830638475085965\n",
      "Epoch 341. Avg accuracy 0.6725124381667938\n",
      "Epoch 342. Avg accuracy 0.6572553900936943\n",
      "Epoch 343. Avg accuracy 0.6398009951434919\n",
      "Epoch 344. Avg accuracy 0.7101368162762466\n",
      "Epoch 345. Avg accuracy 0.6603855724951521\n",
      "Epoch 346. Avg accuracy 0.7098258710026148\n",
      "Epoch 347. Avg accuracy 0.6731757880443364\n",
      "Epoch 348. Avg accuracy 0.6675580431572834\n",
      "Epoch 349. Avg accuracy 0.684556385177878\n",
      "Epoch 350. Avg accuracy 0.6808872305931737\n",
      "Epoch 351. Avg accuracy 0.6538349920837441\n",
      "Epoch 352. Avg accuracy 0.6752487563375217\n",
      "Epoch 353. Avg accuracy 0.6774875625449034\n",
      "Epoch 354. Avg accuracy 0.6728855721393034\n",
      "Epoch 355. Avg accuracy 0.6722429522234409\n",
      "Epoch 356. Avg accuracy 0.670874793138077\n",
      "Epoch 357. Avg accuracy 0.6666459372980678\n",
      "Epoch 358. Avg accuracy 0.6787313436394307\n",
      "Epoch 359. Avg accuracy 0.6600538975563809\n",
      "Epoch 360. Avg accuracy 0.6379975127936596\n",
      "Epoch 361. Avg accuracy 0.675290215964341\n",
      "Epoch 362. Avg accuracy 0.6666252076329283\n",
      "Epoch 363. Avg accuracy 0.6867330020933009\n",
      "Epoch 364. Avg accuracy 0.6526119406543561\n",
      "Epoch 365. Avg accuracy 0.6581882259145898\n",
      "Epoch 366. Avg accuracy 0.6650082922693509\n",
      "Epoch 367. Avg accuracy 0.6955223884155501\n",
      "Epoch 368. Avg accuracy 0.6827529025315052\n",
      "Epoch 369. Avg accuracy 0.6737147599310425\n",
      "Epoch 370. Avg accuracy 0.6410655061996992\n",
      "Epoch 371. Avg accuracy 0.6747097847473562\n",
      "Epoch 372. Avg accuracy 0.664697346995719\n",
      "Epoch 373. Avg accuracy 0.671807628662432\n",
      "Epoch 374. Avg accuracy 0.6806177449463612\n",
      "Epoch 375. Avg accuracy 0.6538142624186046\n",
      "Epoch 376. Avg accuracy 0.7116500830175865\n",
      "Epoch 377. Avg accuracy 0.6690920401568436\n",
      "Epoch 378. Avg accuracy 0.6753316752946199\n",
      "Epoch 379. Avg accuracy 0.7002072971851672\n",
      "Epoch 380. Avg accuracy 0.6358208958782366\n",
      "Epoch 381. Avg accuracy 0.6529436152965868\n",
      "Epoch 382. Avg accuracy 0.6499792705127849\n",
      "Epoch 383. Avg accuracy 0.6983001662130973\n",
      "Epoch 384. Avg accuracy 0.6413142621813722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385. Avg accuracy 0.6289179105663774\n",
      "Epoch 386. Avg accuracy 0.6575663350707855\n",
      "Epoch 387. Avg accuracy 0.6606135988116857\n",
      "Epoch 388. Avg accuracy 0.6520107797722319\n",
      "Epoch 389. Avg accuracy 0.6619402988633113\n",
      "Epoch 390. Avg accuracy 0.6214552239992133\n",
      "Epoch 391. Avg accuracy 0.6697139307041073\n",
      "Epoch 392. Avg accuracy 0.6930140965613559\n",
      "Epoch 393. Avg accuracy 0.6513474295981487\n",
      "Epoch 394. Avg accuracy 0.6657338308457711\n",
      "Epoch 395. Avg accuracy 0.6668117746191832\n",
      "Epoch 396. Avg accuracy 0.6373134329544371\n",
      "Epoch 397. Avg accuracy 0.6392620235533264\n",
      "Epoch 398. Avg accuracy 0.6255804315135254\n",
      "Epoch 399. Avg accuracy 0.6510364846210575\n",
      "Epoch 400. Avg accuracy 0.6503938644086543\n",
      "Epoch 401. Avg accuracy 0.6366915424071734\n",
      "Epoch 402. Avg accuracy 0.6622305144718037\n",
      "Epoch 403. Avg accuracy 0.6367122723688534\n",
      "Epoch 404. Avg accuracy 0.6520107797722319\n",
      "Epoch 405. Avg accuracy 0.6404436156524355\n",
      "Epoch 406. Avg accuracy 0.688971808004142\n",
      "Epoch 407. Avg accuracy 0.6796641794603262\n",
      "Epoch 408. Avg accuracy 0.6859245442632419\n",
      "Epoch 409. Avg accuracy 0.6401741297090825\n",
      "Epoch 410. Avg accuracy 0.6423507466245053\n",
      "Epoch 411. Avg accuracy 0.670315091289691\n",
      "Epoch 412. Avg accuracy 0.6865257051453661\n",
      "Epoch 413. Avg accuracy 0.6603233832031933\n",
      "Epoch 414. Avg accuracy 0.6513681595598287\n",
      "Epoch 415. Avg accuracy 0.6887023220607891\n",
      "Epoch 416. Avg accuracy 0.660945273750457\n",
      "Epoch 417. Avg accuracy 0.6612976786509082\n",
      "Epoch 418. Avg accuracy 0.6495232175831771\n",
      "Epoch 419. Avg accuracy 0.6755597016111535\n",
      "Epoch 420. Avg accuracy 0.6591003320703459\n",
      "Epoch 421. Avg accuracy 0.7041666667852828\n",
      "Epoch 422. Avg accuracy 0.6715796023458984\n",
      "Epoch 423. Avg accuracy 0.6660033170856646\n",
      "Epoch 424. Avg accuracy 0.6600746272215202\n",
      "Epoch 425. Avg accuracy 0.6964552242364457\n",
      "Epoch 426. Avg accuracy 0.6600953568866597\n",
      "Epoch 427. Avg accuracy 0.6668532339494619\n",
      "Epoch 428. Avg accuracy 0.6936359871086196\n",
      "Epoch 429. Avg accuracy 0.6843076286031239\n",
      "Epoch 430. Avg accuracy 0.6208540634136295\n",
      "Epoch 431. Avg accuracy 0.6124378110638898\n",
      "Epoch 432. Avg accuracy 0.6547263682778202\n",
      "Epoch 433. Avg accuracy 0.662831675353928\n",
      "Epoch 434. Avg accuracy 0.6361525708170079\n",
      "Epoch 435. Avg accuracy 0.6752694862992016\n",
      "Epoch 436. Avg accuracy 0.6768656719976397\n",
      "Epoch 437. Avg accuracy 0.6668946935762814\n",
      "Epoch 438. Avg accuracy 0.6874378113011222\n",
      "Epoch 439. Avg accuracy 0.6358208958782366\n",
      "Epoch 440. Avg accuracy 0.661339137981187\n",
      "Epoch 441. Avg accuracy 0.6519485907768136\n",
      "Epoch 442. Avg accuracy 0.6703565509165105\n",
      "Epoch 443. Avg accuracy 0.6544568823344672\n",
      "Epoch 444. Avg accuracy 0.6335613600057156\n",
      "Epoch 445. Avg accuracy 0.6647388063259979\n",
      "Epoch 446. Avg accuracy 0.6308250415384473\n",
      "Epoch 447. Avg accuracy 0.6762852407806549\n",
      "Epoch 448. Avg accuracy 0.6771144279793128\n",
      "Epoch 449. Avg accuracy 0.6395522391618188\n",
      "Epoch 450. Avg accuracy 0.638018242458799\n",
      "Epoch 451. Avg accuracy 0.6467039804553512\n",
      "Epoch 452. Avg accuracy 0.6774461032146245\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-1e07fcdb163f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mbatch_onehot_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#print(batch_onehot_vals.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_onehot_vals\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mavg_accuracy_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbatch_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    onehot_labels = tf.one_hot(labels, len(names), on_value=1., off_value=0., axis=-1)\n",
    "    #print(onehot_labels)\n",
    "    onehot_vals = sess.run(onehot_labels)\n",
    "    batch_size = len(data) // 200\n",
    "    print('batch size', batch_size)\n",
    "    for j in range(0, 1000):\n",
    "        avg_accuracy_val = 0.\n",
    "        batch_count = 0.\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch_data = data[i:i+batch_size, :]\n",
    "            #print(batch_data.shape)\n",
    "            batch_onehot_vals = onehot_vals[i:i+batch_size, :]\n",
    "            #print(batch_onehot_vals.shape)\n",
    "            _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: batch_data, y: batch_onehot_vals})\n",
    "            avg_accuracy_val += accuracy_val\n",
    "            batch_count += 1.\n",
    "        avg_accuracy_val /= batch_count\n",
    "        print('Epoch {}. Avg accuracy {}'.format(j, avg_accuracy_val))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
